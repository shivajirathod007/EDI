{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b240cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shiva\\.conda\\envs\\edi\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6220266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MiniLM embedding model...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================\n",
    "#  LOAD EMBEDDING MODEL (MiniLM)\n",
    "# ============================================================\n",
    "print(\"Loading MiniLM embedding model...\")\n",
    "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def get_embedding(text: str):\n",
    "    return embed_model.encode(text, normalize_embeddings=True).tolist()\n",
    "\n",
    "def cosine_sim(a, b):\n",
    "    return float(np.dot(np.array(a), np.array(b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca369a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "#  IMPORT YOUR FULL CATEGORY RULESET\n",
    "# ============================================================\n",
    "from prompt_memory_rules import PROMPT_MEMORY_RULES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "114b72bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "#  SCORING FUNCTION (for better score distribution)\n",
    "# ============================================================\n",
    "def assign_score(label):\n",
    "    if label == \"highly_relevant\":\n",
    "        return random.uniform(0.70, 1.00)\n",
    "    elif label == \"somewhat_relevant\":\n",
    "        return random.uniform(0.40, 0.69)\n",
    "    else:  # not_relevant\n",
    "        return random.uniform(0.00, 0.29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e54c2fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "#  GENERATE ONE TRAINING SAMPLE\n",
    "# ============================================================\n",
    "def generate_sample(category_def):\n",
    "    category = category_def[\"category\"]\n",
    "\n",
    "    # Select prompt\n",
    "    prompt = random.choice(category_def[\"prompts\"])\n",
    "\n",
    "    # Select relevance group\n",
    "    relevance_type = random.choice(\n",
    "        [\"highly_relevant\"] * 3 + \n",
    "        [\"somewhat_relevant\"] * 2 + \n",
    "        [\"not_relevant\"] * 5\n",
    "    )\n",
    "\n",
    "    # Pick a memory from that relevance group\n",
    "    memory_item, memory_type = random.choice(category_def[relevance_type])\n",
    "\n",
    "    # Embeddings\n",
    "    emb_p = get_embedding(prompt)\n",
    "    emb_m = get_embedding(memory_item)\n",
    "\n",
    "    # Compute semantic similarity\n",
    "    semantic_similarity = cosine_sim(emb_p, emb_m)\n",
    "\n",
    "    # Score assigned (label-based)\n",
    "    relevance_score = assign_score(relevance_type)\n",
    "\n",
    "    return {\n",
    "        \"prompt\": prompt,\n",
    "        \"memory_item\": memory_item,\n",
    "        \"summary\": memory_item,           # optional, can modify later\n",
    "        \"memory_type\": memory_type,\n",
    "        \"category\": category,\n",
    "\n",
    "        \"relevance_label\": relevance_type,\n",
    "        \"relevance_score\": relevance_score,\n",
    "        \"semantic_similarity\": semantic_similarity,\n",
    "\n",
    "        \"prompt_embedding\": emb_p,\n",
    "        \"memory_embedding\": emb_m,\n",
    "    }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33bb907a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Model-1 dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70000/70000 [51:41<00:00, 22.57it/s]  \n",
      "100%|██████████| 1000/1000 [00:36<00:00, 27.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================================================\n",
      "✅ Dataset generation complete!\n",
      "Training file: model1_training_70k.jsonl\n",
      "Validation file: model1_validation_1k.jsonl\n",
      "===========================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "#  MAIN GENERATION LOOP\n",
    "# ============================================================\n",
    "TRAIN_SAMPLES = 70000\n",
    "VAL_SAMPLES = 1000\n",
    "\n",
    "train_path = \"model1_training_70k.jsonl\"\n",
    "val_path = \"model1_validation_1k.jsonl\"\n",
    "\n",
    "print(\"Generating Model-1 dataset...\")\n",
    "\n",
    "with open(train_path, \"w\", encoding=\"utf-8\") as f_train:\n",
    "    for _ in tqdm(range(TRAIN_SAMPLES)):\n",
    "        category_def = random.choice(PROMPT_MEMORY_RULES)\n",
    "        sample = generate_sample(category_def)\n",
    "        f_train.write(json.dumps(sample) + \"\\n\")\n",
    "\n",
    "with open(val_path, \"w\", encoding=\"utf-8\") as f_val:\n",
    "    for _ in tqdm(range(VAL_SAMPLES)):\n",
    "        category_def = random.choice(PROMPT_MEMORY_RULES)\n",
    "        sample = generate_sample(category_def)\n",
    "        f_val.write(json.dumps(sample) + \"\\n\")\n",
    "\n",
    "print(\"\\n===========================================================\")\n",
    "print(\"✅ Dataset generation complete!\")\n",
    "print(\"Training file:\", train_path)\n",
    "print(\"Validation file:\", val_path)\n",
    "print(\"===========================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02a9398",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
